{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statement 2 - Employee Survey Topic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import statements\n",
    "import pandas as pd #data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.feature_extraction.text import CountVectorizer #CountVectorizer Bag of Words\n",
    "from umap import UMAP #UMAP Dimensionality Reduction\n",
    "from bertopic import BERTopic #Topic Modelling\n",
    "from sentence_transformers import SentenceTransformer #Embedding model\n",
    "import torch #Pytorch module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the Data to have a quick peep into the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_identifier</th>\n",
       "      <th>employee_feedback</th>\n",
       "      <th>department</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3565</td>\n",
       "      <td>There's a culture of blame within the company ...</td>\n",
       "      <td>Dept A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7323</td>\n",
       "      <td>The company's approach to feedback and perform...</td>\n",
       "      <td>Dept A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5008</td>\n",
       "      <td>While page limits have been set, some departme...</td>\n",
       "      <td>Dept A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3460</td>\n",
       "      <td>na</td>\n",
       "      <td>Dept A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2179</td>\n",
       "      <td>The culture of collaboration within our team i...</td>\n",
       "      <td>Dept A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_identifier                                  employee_feedback  \\\n",
       "0               3565  There's a culture of blame within the company ...   \n",
       "1               7323  The company's approach to feedback and perform...   \n",
       "2               5008  While page limits have been set, some departme...   \n",
       "3               3460                                                 na   \n",
       "4               2179  The culture of collaboration within our team i...   \n",
       "\n",
       "  department  \n",
       "0     Dept A  \n",
       "1     Dept A  \n",
       "2     Dept A  \n",
       "3     Dept A  \n",
       "4     Dept A  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import data for statement 2\n",
    "data = pd.read_excel(r\"..\\..\\masds002\\DS2-assessment-Simulated-Employee-Feedback.xlsx\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are definitely some rows that have to be filtered such as the na ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_identifier</th>\n",
       "      <th>employee_feedback</th>\n",
       "      <th>department</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>3885</td>\n",
       "      <td>N.A</td>\n",
       "      <td>Dept C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    unique_identifier employee_feedback department\n",
       "62               3885               N.A     Dept C"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data[\"employee_feedback\"].str.lower() == \"n.a\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(data[(data['employee_feedback'].str.lower() == \"na\") | \n",
    "                          (data['employee_feedback'].str.lower().str.strip() == \"n.a.\") |\n",
    "                          (data['employee_feedback'].str.lower() == \"none\") |\n",
    "                          (data['employee_feedback'].str.lower().str.strip() == \"nil\") |\n",
    "                          (data['employee_feedback'].str.lower() == \"no\") |\n",
    "                          (data['employee_feedback'].str.lower() == \"nil.\") |\n",
    "                          (data['employee_feedback'].str.lower() == \"na.\") |\n",
    "                          (data['employee_feedback'].str.lower() == \"n.a.\") |\n",
    "                          (data['employee_feedback'].str.lower() == \"md\") |\n",
    "                          (data['employee_feedback'].str.lower() == \"-\") |\n",
    "                          (data['employee_feedback'].str.lower() == \"--\")].index).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The number of rows has decreased by filtering out the irrelevant rows with placeholder text that do not contribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>unique_identifier</th>\n",
       "      <th>employee_feedback</th>\n",
       "      <th>department</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index, unique_identifier, employee_feedback, department]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data[\"employee_feedback\"].str.lower() == \"na.\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Perform Bertopic on **default parameters** to have a visual inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = data[\"employee_feedback\"]\n",
    "topic_model = BERTopic()\n",
    "topics, probs = topic_model.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>0_and_to_the_is</td>\n",
       "      <td>[and, to, the, is, more, my, work, be, are, in]</td>\n",
       "      <td>[A few points:\\n - The company's culture is ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1_good_na_hear_wfh</td>\n",
       "      <td>[good, na, hear, wfh, many, comments, no, be, ...</td>\n",
       "      <td>[No comments., Good, good to be  hear]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Count                Name  \\\n",
       "0      0    132     0_and_to_the_is   \n",
       "1      1     12  1_good_na_hear_wfh   \n",
       "\n",
       "                                      Representation  \\\n",
       "0    [and, to, the, is, more, my, work, be, are, in]   \n",
       "1  [good, na, hear, wfh, many, comments, no, be, ...   \n",
       "\n",
       "                                 Representative_Docs  \n",
       "0  [A few points:\\n - The company's culture is ge...  \n",
       "1             [No comments., Good, good to be  hear]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('good', 1.0881586029589583),\n",
       " ('na', 0.7516433302915633),\n",
       " ('hear', 0.7516433302915633),\n",
       " ('wfh', 0.6823830044044377),\n",
       " ('many', 0.6823830044044377),\n",
       " ('comments', 0.6823830044044377),\n",
       " ('no', 0.6131769820113188),\n",
       " ('be', 0.3630720539940404),\n",
       " ('to', 0.2628007493428674),\n",
       " ('', 1e-05)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topic(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There is only 2 topics and the representative words of a topic are not meaningful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "      <th>Top_n_words</th>\n",
       "      <th>Probability</th>\n",
       "      <th>Representative_document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>There's a culture of blame within the company ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0_and_to_the_is</td>\n",
       "      <td>[and, to, the, is, more, my, work, be, are, in]</td>\n",
       "      <td>[A few points:\\n - The company's culture is ge...</td>\n",
       "      <td>and - to - the - is - more - my - work - be - ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The company's approach to feedback and perform...</td>\n",
       "      <td>0</td>\n",
       "      <td>0_and_to_the_is</td>\n",
       "      <td>[and, to, the, is, more, my, work, be, are, in]</td>\n",
       "      <td>[A few points:\\n - The company's culture is ge...</td>\n",
       "      <td>and - to - the - is - more - my - work - be - ...</td>\n",
       "      <td>0.799605</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>While page limits have been set, some departme...</td>\n",
       "      <td>0</td>\n",
       "      <td>0_and_to_the_is</td>\n",
       "      <td>[and, to, the, is, more, my, work, be, are, in]</td>\n",
       "      <td>[A few points:\\n - The company's culture is ge...</td>\n",
       "      <td>and - to - the - is - more - my - work - be - ...</td>\n",
       "      <td>0.910277</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The culture of collaboration within our team i...</td>\n",
       "      <td>0</td>\n",
       "      <td>0_and_to_the_is</td>\n",
       "      <td>[and, to, the, is, more, my, work, be, are, in]</td>\n",
       "      <td>[A few points:\\n - The company's culture is ge...</td>\n",
       "      <td>and - to - the - is - more - my - work - be - ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>While the workload can be overwhelming at time...</td>\n",
       "      <td>0</td>\n",
       "      <td>0_and_to_the_is</td>\n",
       "      <td>[and, to, the, is, more, my, work, be, are, in]</td>\n",
       "      <td>[A few points:\\n - The company's culture is ge...</td>\n",
       "      <td>and - to - the - is - more - my - work - be - ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>Our documentation is thorough. Onboarding new ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0_and_to_the_is</td>\n",
       "      <td>[and, to, the, is, more, my, work, be, are, in]</td>\n",
       "      <td>[A few points:\\n - The company's culture is ge...</td>\n",
       "      <td>and - to - the - is - more - my - work - be - ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Feedback flows freely. Suggestions to improve ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0_and_to_the_is</td>\n",
       "      <td>[and, to, the, is, more, my, work, be, are, in]</td>\n",
       "      <td>[A few points:\\n - The company's culture is ge...</td>\n",
       "      <td>and - to - the - is - more - my - work - be - ...</td>\n",
       "      <td>0.938481</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>Our team leads by example. The standards they ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0_and_to_the_is</td>\n",
       "      <td>[and, to, the, is, more, my, work, be, are, in]</td>\n",
       "      <td>[A few points:\\n - The company's culture is ge...</td>\n",
       "      <td>and - to - the - is - more - my - work - be - ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>Cross-training and job shadowing help broaden ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0_and_to_the_is</td>\n",
       "      <td>[and, to, the, is, more, my, work, be, are, in]</td>\n",
       "      <td>[A few points:\\n - The company's culture is ge...</td>\n",
       "      <td>and - to - the - is - more - my - work - be - ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Virtual collaboration tools and communication ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0_and_to_the_is</td>\n",
       "      <td>[and, to, the, is, more, my, work, be, are, in]</td>\n",
       "      <td>[A few points:\\n - The company's culture is ge...</td>\n",
       "      <td>and - to - the - is - more - my - work - be - ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Document  Topic  \\\n",
       "0    There's a culture of blame within the company ...      0   \n",
       "1    The company's approach to feedback and perform...      0   \n",
       "2    While page limits have been set, some departme...      0   \n",
       "3    The culture of collaboration within our team i...      0   \n",
       "4    While the workload can be overwhelming at time...      0   \n",
       "..                                                 ...    ...   \n",
       "139  Our documentation is thorough. Onboarding new ...      0   \n",
       "140  Feedback flows freely. Suggestions to improve ...      0   \n",
       "141  Our team leads by example. The standards they ...      0   \n",
       "142  Cross-training and job shadowing help broaden ...      0   \n",
       "143  Virtual collaboration tools and communication ...      0   \n",
       "\n",
       "                Name                                   Representation  \\\n",
       "0    0_and_to_the_is  [and, to, the, is, more, my, work, be, are, in]   \n",
       "1    0_and_to_the_is  [and, to, the, is, more, my, work, be, are, in]   \n",
       "2    0_and_to_the_is  [and, to, the, is, more, my, work, be, are, in]   \n",
       "3    0_and_to_the_is  [and, to, the, is, more, my, work, be, are, in]   \n",
       "4    0_and_to_the_is  [and, to, the, is, more, my, work, be, are, in]   \n",
       "..               ...                                              ...   \n",
       "139  0_and_to_the_is  [and, to, the, is, more, my, work, be, are, in]   \n",
       "140  0_and_to_the_is  [and, to, the, is, more, my, work, be, are, in]   \n",
       "141  0_and_to_the_is  [and, to, the, is, more, my, work, be, are, in]   \n",
       "142  0_and_to_the_is  [and, to, the, is, more, my, work, be, are, in]   \n",
       "143  0_and_to_the_is  [and, to, the, is, more, my, work, be, are, in]   \n",
       "\n",
       "                                   Representative_Docs  \\\n",
       "0    [A few points:\\n - The company's culture is ge...   \n",
       "1    [A few points:\\n - The company's culture is ge...   \n",
       "2    [A few points:\\n - The company's culture is ge...   \n",
       "3    [A few points:\\n - The company's culture is ge...   \n",
       "4    [A few points:\\n - The company's culture is ge...   \n",
       "..                                                 ...   \n",
       "139  [A few points:\\n - The company's culture is ge...   \n",
       "140  [A few points:\\n - The company's culture is ge...   \n",
       "141  [A few points:\\n - The company's culture is ge...   \n",
       "142  [A few points:\\n - The company's culture is ge...   \n",
       "143  [A few points:\\n - The company's culture is ge...   \n",
       "\n",
       "                                           Top_n_words  Probability  \\\n",
       "0    and - to - the - is - more - my - work - be - ...     1.000000   \n",
       "1    and - to - the - is - more - my - work - be - ...     0.799605   \n",
       "2    and - to - the - is - more - my - work - be - ...     0.910277   \n",
       "3    and - to - the - is - more - my - work - be - ...     1.000000   \n",
       "4    and - to - the - is - more - my - work - be - ...     1.000000   \n",
       "..                                                 ...          ...   \n",
       "139  and - to - the - is - more - my - work - be - ...     1.000000   \n",
       "140  and - to - the - is - more - my - work - be - ...     0.938481   \n",
       "141  and - to - the - is - more - my - work - be - ...     1.000000   \n",
       "142  and - to - the - is - more - my - work - be - ...     1.000000   \n",
       "143  and - to - the - is - more - my - work - be - ...     1.000000   \n",
       "\n",
       "     Representative_document  \n",
       "0                      False  \n",
       "1                      False  \n",
       "2                      False  \n",
       "3                      False  \n",
       "4                      False  \n",
       "..                       ...  \n",
       "139                    False  \n",
       "140                    False  \n",
       "141                    False  \n",
       "142                    False  \n",
       "143                    False  \n",
       "\n",
       "[144 rows x 8 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_document_info(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for GPU Acceleration since LLM will be used for text generation later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 this is the device\n"
     ]
    }
   ],
   "source": [
    "device = 0 if torch.cuda.is_available() else -1\n",
    "print(device,\"this is the device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1463516b22f9491fbe1ffed135d48332",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79de69d542f94beca44604da3ac3a59c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CTransformersModel has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from ctransformers import AutoModelForCausalLM\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "\n",
    "# Set gpu_layers to the number of layers to offload to GPU. Set to 0 if no GPU acceleration is available on your system.\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"TheBloke/zephyr-7B-alpha-GGUF\",\n",
    "    model_file=\"zephyr-7b-alpha.Q4_K_M.gguf\",\n",
    "    model_type=\"mistral\",\n",
    "    gpu_layers=50,\n",
    "    hf=True\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"HuggingFaceH4/zephyr-7b-alpha\")\n",
    "\n",
    "# Pipeline\n",
    "generator = pipeline(\n",
    "    model=model, tokenizer=tokenizer,\n",
    "    task='text-generation',\n",
    "    max_new_tokens=50,\n",
    "    repetition_penalty=1.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"<|system|>You are a helpful, respectful and honest assistant for labeling topics..</s>\n",
    "<|user|>\n",
    "I have a topic that contains the following documents:\n",
    "[DOCUMENTS]\n",
    "\n",
    "The topic is described by the following keywords: '[KEYWORDS]'.\n",
    "\n",
    "Based on the information about the topic above, please describe the profile of the employees. Make sure you describe the\n",
    "profile of the employees only using the documents and keywords above.</s>\n",
    "<|assistant|>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic.representation import TextGeneration\n",
    "\n",
    "# Text generation with Zephyr\n",
    "zephyr = TextGeneration(generator, prompt=prompt)\n",
    "representation_model = {\"Zephyr\": zephyr}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create Bertopic with **better Embedding Model**, **lower n_neighbours=3** to have more localised topics, **lower min_topic_size** requiring fewer rows to form a topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of tokens (513) exceeded maximum context length (512).\n",
      "Number of tokens (514) exceeded maximum context length (512).\n",
      "Number of tokens (515) exceeded maximum context length (512).\n",
      "Number of tokens (516) exceeded maximum context length (512).\n",
      "Number of tokens (517) exceeded maximum context length (512).\n",
      "Number of tokens (518) exceeded maximum context length (512).\n",
      "Number of tokens (519) exceeded maximum context length (512).\n",
      "Number of tokens (520) exceeded maximum context length (512).\n",
      "Number of tokens (521) exceeded maximum context length (512).\n",
      "Number of tokens (522) exceeded maximum context length (512).\n",
      "Number of tokens (523) exceeded maximum context length (512).\n",
      "Number of tokens (524) exceeded maximum context length (512).\n",
      "Number of tokens (525) exceeded maximum context length (512).\n",
      "Number of tokens (526) exceeded maximum context length (512).\n",
      "Number of tokens (527) exceeded maximum context length (512).\n",
      "Number of tokens (528) exceeded maximum context length (512).\n",
      "Number of tokens (529) exceeded maximum context length (512).\n",
      "Number of tokens (530) exceeded maximum context length (512).\n",
      "Number of tokens (531) exceeded maximum context length (512).\n",
      "Number of tokens (532) exceeded maximum context length (512).\n",
      "Number of tokens (533) exceeded maximum context length (512).\n",
      "Number of tokens (534) exceeded maximum context length (512).\n",
      "Number of tokens (535) exceeded maximum context length (512).\n",
      "Number of tokens (536) exceeded maximum context length (512).\n",
      "Number of tokens (537) exceeded maximum context length (512).\n",
      "Number of tokens (538) exceeded maximum context length (512).\n",
      "Number of tokens (539) exceeded maximum context length (512).\n",
      "Number of tokens (540) exceeded maximum context length (512).\n",
      "Number of tokens (541) exceeded maximum context length (512).\n",
      "Number of tokens (542) exceeded maximum context length (512).\n",
      "Number of tokens (543) exceeded maximum context length (512).\n",
      "Number of tokens (544) exceeded maximum context length (512).\n",
      "Number of tokens (545) exceeded maximum context length (512).\n",
      "Number of tokens (546) exceeded maximum context length (512).\n",
      "Number of tokens (547) exceeded maximum context length (512).\n",
      "Number of tokens (570) exceeded maximum context length (512).\n",
      "Number of tokens (571) exceeded maximum context length (512).\n",
      "Number of tokens (572) exceeded maximum context length (512).\n",
      "Number of tokens (573) exceeded maximum context length (512).\n",
      "Number of tokens (574) exceeded maximum context length (512).\n",
      "Number of tokens (575) exceeded maximum context length (512).\n",
      "Number of tokens (576) exceeded maximum context length (512).\n",
      "Number of tokens (577) exceeded maximum context length (512).\n",
      "Number of tokens (578) exceeded maximum context length (512).\n",
      "Number of tokens (579) exceeded maximum context length (512).\n",
      "Number of tokens (580) exceeded maximum context length (512).\n",
      "Number of tokens (581) exceeded maximum context length (512).\n",
      "Number of tokens (582) exceeded maximum context length (512).\n",
      "Number of tokens (583) exceeded maximum context length (512).\n",
      "Number of tokens (584) exceeded maximum context length (512).\n",
      "Number of tokens (585) exceeded maximum context length (512).\n",
      "Number of tokens (586) exceeded maximum context length (512).\n",
      "Number of tokens (587) exceeded maximum context length (512).\n",
      "Number of tokens (588) exceeded maximum context length (512).\n",
      "Number of tokens (589) exceeded maximum context length (512).\n",
      "Number of tokens (590) exceeded maximum context length (512).\n",
      "Number of tokens (591) exceeded maximum context length (512).\n",
      "Number of tokens (592) exceeded maximum context length (512).\n",
      "Number of tokens (593) exceeded maximum context length (512).\n",
      "Number of tokens (594) exceeded maximum context length (512).\n",
      "Number of tokens (595) exceeded maximum context length (512).\n",
      "Number of tokens (596) exceeded maximum context length (512).\n",
      "Number of tokens (597) exceeded maximum context length (512).\n",
      "Number of tokens (598) exceeded maximum context length (512).\n",
      "Number of tokens (599) exceeded maximum context length (512).\n",
      "Number of tokens (600) exceeded maximum context length (512).\n",
      "Number of tokens (601) exceeded maximum context length (512).\n",
      "Number of tokens (602) exceeded maximum context length (512).\n",
      "Number of tokens (603) exceeded maximum context length (512).\n",
      "Number of tokens (604) exceeded maximum context length (512).\n",
      "Number of tokens (605) exceeded maximum context length (512).\n",
      "Number of tokens (606) exceeded maximum context length (512).\n",
      "Number of tokens (607) exceeded maximum context length (512).\n",
      "Number of tokens (608) exceeded maximum context length (512).\n",
      "Number of tokens (609) exceeded maximum context length (512).\n",
      "Number of tokens (610) exceeded maximum context length (512).\n",
      "Number of tokens (611) exceeded maximum context length (512).\n",
      "Number of tokens (612) exceeded maximum context length (512).\n",
      "Number of tokens (613) exceeded maximum context length (512).\n",
      "Number of tokens (614) exceeded maximum context length (512).\n",
      "Number of tokens (615) exceeded maximum context length (512).\n",
      "Number of tokens (616) exceeded maximum context length (512).\n",
      "Number of tokens (617) exceeded maximum context length (512).\n",
      "Number of tokens (618) exceeded maximum context length (512).\n",
      "Number of tokens (619) exceeded maximum context length (512).\n",
      "Number of tokens (699) exceeded maximum context length (512).\n",
      "Number of tokens (700) exceeded maximum context length (512).\n",
      "Number of tokens (701) exceeded maximum context length (512).\n",
      "Number of tokens (702) exceeded maximum context length (512).\n",
      "Number of tokens (703) exceeded maximum context length (512).\n",
      "Number of tokens (704) exceeded maximum context length (512).\n",
      "Number of tokens (705) exceeded maximum context length (512).\n",
      "Number of tokens (706) exceeded maximum context length (512).\n",
      "Number of tokens (707) exceeded maximum context length (512).\n",
      "Number of tokens (708) exceeded maximum context length (512).\n",
      "Number of tokens (709) exceeded maximum context length (512).\n",
      "Number of tokens (710) exceeded maximum context length (512).\n",
      "Number of tokens (711) exceeded maximum context length (512).\n",
      "Number of tokens (712) exceeded maximum context length (512).\n",
      "Number of tokens (713) exceeded maximum context length (512).\n",
      "Number of tokens (714) exceeded maximum context length (512).\n",
      "Number of tokens (715) exceeded maximum context length (512).\n",
      "Number of tokens (716) exceeded maximum context length (512).\n",
      "Number of tokens (717) exceeded maximum context length (512).\n",
      "Number of tokens (718) exceeded maximum context length (512).\n",
      "Number of tokens (719) exceeded maximum context length (512).\n",
      "Number of tokens (720) exceeded maximum context length (512).\n",
      "Number of tokens (721) exceeded maximum context length (512).\n",
      "Number of tokens (722) exceeded maximum context length (512).\n",
      "Number of tokens (723) exceeded maximum context length (512).\n",
      "Number of tokens (724) exceeded maximum context length (512).\n",
      "Number of tokens (725) exceeded maximum context length (512).\n",
      "Number of tokens (726) exceeded maximum context length (512).\n",
      "Number of tokens (727) exceeded maximum context length (512).\n",
      "Number of tokens (728) exceeded maximum context length (512).\n",
      "Number of tokens (729) exceeded maximum context length (512).\n",
      "Number of tokens (730) exceeded maximum context length (512).\n",
      "Number of tokens (731) exceeded maximum context length (512).\n",
      "Number of tokens (732) exceeded maximum context length (512).\n",
      "Number of tokens (733) exceeded maximum context length (512).\n",
      "Number of tokens (734) exceeded maximum context length (512).\n",
      "Number of tokens (735) exceeded maximum context length (512).\n",
      "Number of tokens (736) exceeded maximum context length (512).\n",
      "Number of tokens (737) exceeded maximum context length (512).\n",
      "Number of tokens (738) exceeded maximum context length (512).\n",
      "Number of tokens (739) exceeded maximum context length (512).\n",
      "Number of tokens (740) exceeded maximum context length (512).\n",
      "Number of tokens (741) exceeded maximum context length (512).\n",
      "Number of tokens (742) exceeded maximum context length (512).\n",
      "Number of tokens (743) exceeded maximum context length (512).\n",
      "Number of tokens (744) exceeded maximum context length (512).\n",
      "Number of tokens (745) exceeded maximum context length (512).\n",
      "Number of tokens (746) exceeded maximum context length (512).\n",
      "Number of tokens (747) exceeded maximum context length (512).\n",
      "Number of tokens (748) exceeded maximum context length (512).\n",
      "Number of tokens (513) exceeded maximum context length (512).\n",
      "Number of tokens (514) exceeded maximum context length (512).\n",
      "Number of tokens (515) exceeded maximum context length (512).\n",
      "Number of tokens (516) exceeded maximum context length (512).\n",
      "Number of tokens (517) exceeded maximum context length (512).\n",
      "Number of tokens (518) exceeded maximum context length (512).\n",
      "Number of tokens (519) exceeded maximum context length (512).\n",
      "Number of tokens (520) exceeded maximum context length (512).\n",
      "Number of tokens (521) exceeded maximum context length (512).\n",
      "Number of tokens (522) exceeded maximum context length (512).\n",
      "Number of tokens (523) exceeded maximum context length (512).\n",
      "Number of tokens (513) exceeded maximum context length (512).\n",
      "Number of tokens (514) exceeded maximum context length (512).\n",
      "Number of tokens (515) exceeded maximum context length (512).\n",
      "Number of tokens (516) exceeded maximum context length (512).\n",
      "Number of tokens (517) exceeded maximum context length (512).\n",
      "Number of tokens (518) exceeded maximum context length (512).\n",
      "Number of tokens (519) exceeded maximum context length (512).\n",
      "Number of tokens (520) exceeded maximum context length (512).\n",
      "Number of tokens (521) exceeded maximum context length (512).\n",
      "Number of tokens (522) exceeded maximum context length (512).\n"
     ]
    }
   ],
   "source": [
    "vectorizer_model = CountVectorizer(stop_words=\"english\")\n",
    "#sentence_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "sentence_model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "#embeddings = sentence_model.encode(docs, show_progress_bar=False)\n",
    "umap_model = UMAP(n_neighbors=3, n_components=5, min_dist=0.0, metric='cosine',random_state=42)\n",
    "topic_model = BERTopic(vectorizer_model=vectorizer_model,min_topic_size=5, \n",
    "                       umap_model=umap_model,embedding_model=sentence_model,representation_model=representation_model)\n",
    "topics, probs = topic_model.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Zephyr</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>7</td>\n",
       "      <td>-1_job_passion_provides_bored</td>\n",
       "      <td>[job, passion, provides, bored, mission, organ...</td>\n",
       "      <td>[\\nThe employees in this context appear to be ...</td>\n",
       "      <td>[I feel bored and unchallenged in my job., My ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0_team_work_collaboration_positive</td>\n",
       "      <td>[team, work, collaboration, positive, environm...</td>\n",
       "      <td>[\\nThe employees mentioned in these documents ...</td>\n",
       "      <td>[The culture of collaboration within our team ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>1_company_day_difficult_feel</td>\n",
       "      <td>[company, day, difficult, feel, lack, trust, c...</td>\n",
       "      <td>[\\nTopic: Communication, 'Company Culture, 'Co...</td>\n",
       "      <td>[There's a lack of transparency within the com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>2_career_opportunities_feel_manager</td>\n",
       "      <td>[career, opportunities, feel, manager, growth,...</td>\n",
       "      <td>[\\n1|&gt;\\nTopic:\\nLabel|&gt;\\n1|&gt;\\n1|&gt;\\n1|&gt;\\n1|&gt;\\n1...</td>\n",
       "      <td>[The company's commitment to professional deve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>3_recognition_rewards_giving_incentives</td>\n",
       "      <td>[recognition, rewards, giving, incentives, eff...</td>\n",
       "      <td>[\\nThe employees mentioned in these documents ...</td>\n",
       "      <td>[Leaders provide clear direction by giving sug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>4_investment_benefits_company_package</td>\n",
       "      <td>[investment, benefits, company, package, healt...</td>\n",
       "      <td>[\\nThe employees mentioned in this topic seem ...</td>\n",
       "      <td>[While the company offers competitive compensa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>5_work_balance_life_workload</td>\n",
       "      <td>[work, balance, life, workload, hours, availab...</td>\n",
       "      <td>[\\nThe employees in this context seem to vary ...</td>\n",
       "      <td>[While the workload can be overwhelming at tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>6_good_hear_wfh_comments</td>\n",
       "      <td>[good, hear, wfh, comments, , , , , , ]</td>\n",
       "      <td>[\\nBased solely on the provided documents and ...</td>\n",
       "      <td>[No comments., Good, good to be  hear]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7_feedback_reviews_performance_helpful</td>\n",
       "      <td>[feedback, reviews, performance, helpful, year...</td>\n",
       "      <td>[\\nThe employees mentioned in these documents ...</td>\n",
       "      <td>[The company's approach to feedback and perfor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Count                                     Name  \\\n",
       "0     -1      7            -1_job_passion_provides_bored   \n",
       "1      0     40       0_team_work_collaboration_positive   \n",
       "2      1     23             1_company_day_difficult_feel   \n",
       "3      2     21      2_career_opportunities_feel_manager   \n",
       "4      3     14  3_recognition_rewards_giving_incentives   \n",
       "5      4     13    4_investment_benefits_company_package   \n",
       "6      5     10             5_work_balance_life_workload   \n",
       "7      6      9                 6_good_hear_wfh_comments   \n",
       "8      7      7   7_feedback_reviews_performance_helpful   \n",
       "\n",
       "                                      Representation  \\\n",
       "0  [job, passion, provides, bored, mission, organ...   \n",
       "1  [team, work, collaboration, positive, environm...   \n",
       "2  [company, day, difficult, feel, lack, trust, c...   \n",
       "3  [career, opportunities, feel, manager, growth,...   \n",
       "4  [recognition, rewards, giving, incentives, eff...   \n",
       "5  [investment, benefits, company, package, healt...   \n",
       "6  [work, balance, life, workload, hours, availab...   \n",
       "7            [good, hear, wfh, comments, , , , , , ]   \n",
       "8  [feedback, reviews, performance, helpful, year...   \n",
       "\n",
       "                                              Zephyr  \\\n",
       "0  [\\nThe employees in this context appear to be ...   \n",
       "1  [\\nThe employees mentioned in these documents ...   \n",
       "2  [\\nTopic: Communication, 'Company Culture, 'Co...   \n",
       "3  [\\n1|>\\nTopic:\\nLabel|>\\n1|>\\n1|>\\n1|>\\n1|>\\n1...   \n",
       "4  [\\nThe employees mentioned in these documents ...   \n",
       "5  [\\nThe employees mentioned in this topic seem ...   \n",
       "6  [\\nThe employees in this context seem to vary ...   \n",
       "7  [\\nBased solely on the provided documents and ...   \n",
       "8  [\\nThe employees mentioned in these documents ...   \n",
       "\n",
       "                                 Representative_Docs  \n",
       "0  [I feel bored and unchallenged in my job., My ...  \n",
       "1  [The culture of collaboration within our team ...  \n",
       "2  [There's a lack of transparency within the com...  \n",
       "3  [The company's commitment to professional deve...  \n",
       "4  [Leaders provide clear direction by giving sug...  \n",
       "5  [While the company offers competitive compensa...  \n",
       "6  [While the workload can be overwhelming at tim...  \n",
       "7             [No comments., Good, good to be  hear]  \n",
       "8  [The company's approach to feedback and perfor...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'topic_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtopic_model\u001b[49m\u001b[38;5;241m.\u001b[39mvisualize_heatmap()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'topic_model' is not defined"
     ]
    }
   ],
   "source": [
    "topic_model.visualize_heatmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'topic_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Run the visualization with the original embeddings\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtopic_model\u001b[49m\u001b[38;5;241m.\u001b[39mvisualize_documents(docs)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'topic_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Run the visualization with the original embeddings\n",
    "topic_model.visualize_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with the original embeddings\n",
    "topic_model.visualize_document_datamap(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"Document\": docs, \"Topic\": topic_model.topics_})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"Topic\"] == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce outliers using the `embeddings` strategy\n",
    "new_topics = topic_model.reduce_outliers(docs, topics, strategy=\"embeddings\", threshold=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_model = CountVectorizer(stop_words=\"english\")\n",
    "#umap_model = UMAP(n_neighbors=3, n_components=5, min_dist=0.0, metric='cosine')\n",
    "\n",
    "topic_model.update_topics(docs, topics=new_topics, vectorizer_model=vectorizer_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the visualization with the original embeddings\n",
    "topic_model.visualize_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with the original embeddings\n",
    "topic_model.visualize_document_datamap(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_per_class = topic_model.topics_per_class(docs, \n",
    "    classes=data.department)\n",
    "\n",
    "topic_model.visualize_topics_per_class(topics_per_class, \n",
    "    top_n_topics=10, normalize_frequency = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_per_class = topic_model.topics_per_class(docs, \n",
    "    classes=data.department)\n",
    "\n",
    "topic_model.visualize_topics_per_class(topics_per_class, top_n_topics=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_barchart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_2 = topic_model.get_representative_docs(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mas_statement_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
